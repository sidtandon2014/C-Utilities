{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Downloading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will help you in downloading the dataset stored in you Azure Machine Learning Service Workspace:\n",
    "\n",
    "**NOTE**: We recommend storing your *Azure Credentials in Secrets, Azure Key Vault, or Environment Variables*\n",
    "\n",
    "*You only need to run it once**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "SUBSCRIPTION_ID = os.getenv('SUBSCRIPTION_ID')\n",
    "RESOURCE_GROUP = os.getenv('RESOURCE_GROUP')\n",
    "WORKSPACENAME = os.getenv('WORKSPACENAME')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# azureml-core of version 1.0.72 or higher is required\n",
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "subscription_id = SUBSCRIPTION_ID\n",
    "resource_group = RESOURCE_GROUP\n",
    "workspace_name = WORKSPACE\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "\n",
    "dataset = Dataset.get_by_name(workspace, name='insurance_claims_data', version=\"1\")\n",
    "dataset.download(target_path='.', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Importing libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We typically recommend importing libraries beforehand. That will help you identify some dependency issues before even loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.figure_factory as ff\n",
    "import cufflinks as cf\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.covariance import EmpiricalCovariance, MinCovDet\n",
    "\n",
    "from interpret import show\n",
    "from interpret.data import ClassHistogram\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "\n",
    "import statistics\n",
    "import hdbscan\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Experiment, Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Reading downloaded data into dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, the file is going to be stored in the local file system that you are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"insurance_claims_data.csv\")\n",
    "target_variable = 'fraud_reported'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Using info() method to understand the data schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this you will understand number of missing samples and the type of each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Formatting target variable into Boolean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will help in the model creation and evaluation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[target_variable] = [1 if i=='Y' else 0 for i in df[target_variable]]\n",
    "df['incident_hour_of_the_day'] = pd.Categorical(df['incident_hour_of_the_day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Data Profiling (Unidimensional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going understand the main characteristics of the different features and the target an unidimensional way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_profiling.ProfileReport(df, explorative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Data Profiling (With reference to Target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, since our target is binary, we recommend the following types of visualizations:\n",
    "- **For categorial independent variables**: We recommend visualizing the percentage of the target class vs. each class of the independent variable.\n",
    "- **For continuous independent variables**: We recommend splitting the data in bins visualizing the percentage of the target class vs. each bin in the independent variable. We also recommend using scatterplots in cases where dependent variable is continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1. Percentage of fraud by Gender. | Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df[['insured_sex','fraud_reported']].groupby(['insured_sex'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='insured_sex',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df[['insured_sex','fraud_reported']].groupby(['insured_sex'], as_index = False).count().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='insured_sex',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2. Percentage of fraud by Auto Model. | Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,5))\n",
    "temp = df[['auto_model','fraud_reported']].groupby(['auto_model'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='auto_model',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,5))\n",
    "temp = df[['auto_model','fraud_reported']].groupby(['auto_model'], as_index = False).count().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='auto_model',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3. Percentage of fraud by Auto Make. | Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "temp = df[['auto_make','fraud_reported']].groupby(['auto_make'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='auto_make',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "temp = df[['auto_make','fraud_reported']].groupby(['auto_make'], as_index = False).count().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='auto_make',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4. Percentage of fraud by Police Report Available. | Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "temp = df[['police_report_available','fraud_reported']].groupby(['police_report_available'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='police_report_available',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "temp = df[['police_report_available','fraud_reported']].groupby(['police_report_available'], as_index = False).count().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='police_report_available',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5. Percentage of fraud by Property Damage. | Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "temp = df[['property_damage','fraud_reported']].groupby(['property_damage'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='property_damage',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "temp = df[['property_damage','fraud_reported']].groupby(['property_damage'], as_index = False).count().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='property_damage',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.6. Percentage of fraud by Incident City. | Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "temp = df[['incident_city','fraud_reported']].groupby(['incident_city'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='incident_city',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "temp = df[['incident_city','fraud_reported']].groupby(['incident_city'], as_index = False).count().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='incident_city',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.7. Percentage of fraud by Incident City. | Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "temp = df[['incident_state','fraud_reported']].groupby(['incident_state'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='incident_state',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "temp = df[['incident_state','fraud_reported']].groupby(['incident_state'], as_index = False).count().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='incident_state',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.8. Percentage of fraud by Authorities contacted. | Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "temp = df[['authorities_contacted','fraud_reported']].groupby(['authorities_contacted'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='authorities_contacted',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "temp = df[['authorities_contacted','fraud_reported']].groupby(['authorities_contacted'], as_index = False).count().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='authorities_contacted',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.9. Percentage of fraud by incident severity. | Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "temp = df[['incident_severity','fraud_reported']].groupby(['incident_severity'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='incident_severity',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "temp = df[['incident_severity','fraud_reported']].groupby(['incident_severity'], as_index = False).count().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='incident_severity',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.10. Percentage of fraud by Colision Type. | Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "temp = df[['collision_type','fraud_reported']].groupby(['collision_type'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='collision_type',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "temp = df[['collision_type','fraud_reported']].groupby(['collision_type'], as_index = False).count().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='collision_type',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.11. Percentage of fraud by Incident Type. | Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "temp = df[['incident_type','fraud_reported']].groupby(['incident_type'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='incident_type',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "temp = df[['incident_type','fraud_reported']].groupby(['incident_type'], as_index = False).count().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='incident_type',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.12. Percentage of fraud by Incident Day and Month. | Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['incident_date'] = pd.to_datetime(df['incident_date'], errors = 'coerce')\n",
    "\n",
    "# extracting days and month from date\n",
    "df['incident_month'] = df['incident_date'].dt.month\n",
    "df['incident_day'] = df['incident_date'].dt.day\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "temp = df[['incident_month','fraud_reported']].groupby(['incident_month'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='incident_month',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "temp = df[['incident_day','fraud_reported']].groupby(['incident_day'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='incident_day',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.13. Percentage of fraud by Insured Relationship. | Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "temp = df[['insured_relationship','fraud_reported']].groupby(['insured_relationship'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='insured_relationship',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "temp = df[['insured_relationship','fraud_reported']].groupby(['insured_relationship'], as_index = False).count().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='insured_relationship',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.14. Percentage of fraud by Insured Hobbies. | Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,5))\n",
    "temp = df[['insured_hobbies','fraud_reported']].groupby(['insured_hobbies'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='insured_hobbies',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,5))\n",
    "temp = df[['insured_hobbies','fraud_reported']].groupby(['insured_hobbies'], as_index = False).count().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='insured_hobbies',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.15. Percentage of fraud by Insured Occupation. | Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,5))\n",
    "temp = df[['insured_occupation','fraud_reported']].groupby(['insured_occupation'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='insured_occupation',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,5))\n",
    "temp = df[['insured_occupation','fraud_reported']].groupby(['insured_occupation'], as_index = False).count().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='insured_occupation',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.16. Percentage of fraud by Insured Education Level. | Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "temp = df[['insured_education_level','fraud_reported']].groupby(['insured_education_level'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='insured_education_level',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "temp = df[['insured_education_level','fraud_reported']].groupby(['insured_education_level'], as_index = False).count().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='insured_education_level',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.17. Percentage of fraud by policy CSL. | Cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CSL** stands for Combined Single Limit\n",
    "\n",
    "**CSL** is a single number that describes the predetermined limit for the combined total of the **Bodily Injury \n",
    "Liability** Coverage and **Property Damage Liability** coverage per occurrence or accident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "temp = df[['policy_csl','fraud_reported']].groupby(['policy_csl'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='policy_csl',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "temp = df[['policy_csl','fraud_reported']].groupby(['policy_csl'], as_index = False).count().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='policy_csl',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.18. Percentage of fraud vs. Auto Year | Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "temp = df[['auto_year','fraud_reported']].groupby(['auto_year'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='auto_year',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "temp = df[['auto_year','fraud_reported']].groupby(['auto_year'], as_index = False).count().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='auto_year',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.19. Approach using the **Interpret** library from Microsoft Research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information [Here.](https://github.com/interpretml/interpret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ignore_initial = ['policy_number', 'policy_bind_date', 'incident_date', 'incident_location', 'insured_zip', 'auto_model', 'fraud_reported']\n",
    "X = df.drop(features_ignore_initial, axis=1)\n",
    "y = df[target_variable].values\n",
    "\n",
    "from interpret.data import ClassHistogram\n",
    "\n",
    "hist = ClassHistogram().explain_data(X, y, name = 'Train Data')\n",
    "show(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7:  Insights from Data Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8:  Outlier and Extreme values identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8.1: Types of outliers and extreme values:\n",
    "\n",
    "Pretty much all datasets contain outliers or extreme values, we should be very aware of them, the can difficult the capacity of generalization of Machine Learning models. \n",
    "\n",
    "Most common causes of outliers on a dataset:\n",
    "\n",
    "- **Data entry** errors: human errors.\n",
    "- **Measurement** errors: instrument errors.\n",
    "- **Experimental** errors: data extraction or experiment planning/executing errors.\n",
    "- **Intentional**: dummy outliers made to test detection methods.\n",
    "- **Data processing** errors: data manipulation or data set unintended mutations.\n",
    "- **Sampling** errors: extracting or mixing data from wrong or various sources.\n",
    "- **Natural**: not an error, novelties in data. ***We might want to keep these*** as the can contain important information on the data.\n",
    "\n",
    "In the process of producing, collecting, processing and analyzing data, outliers can come from many sources and hide in many dimensions. Those that are not a product of an error are called **novelties.**\n",
    "\n",
    "\n",
    "[More detailed information can be found here.](https://towardsdatascience.com/a-brief-overview-of-outlier-detection-techniques-1e0b2c19e561)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8.2: Approaches to outlier and extreme values identification:\n",
    "\n",
    "There are two general categories of approached for **Outlier Detection**:\n",
    "- **Parametric** approaches: these assume that the data has some underlying distribution such as normal distribution.\n",
    "- **Nonparametric** approaches: there is no requirements on the underlying distribution.\n",
    "\n",
    "Additionally, you can conduct your **Outlier Detection** in any number of features:\n",
    "- You can use a **Single** feature.\n",
    "- Or you can use a **Subset** of features.\n",
    "\n",
    "\n",
    "There are virtually infinite approaches (and combination) that help in the outlier identification process. Following you will find some of the approaches that we use\n",
    "\n",
    "- **Heuristics**: because experience or because observations with certain (pre-defined) characteristics are always threated differently from the customers they sometimes market to either exclude them from the process or to specifically observe the behavior of the models for them.\n",
    "- **Z-Score or Extreme Value Analysis (EVA)**: parametric | [Theory (EVA)](https://www.sciencedirect.com/science/article/pii/S0963869517300488) | [Python Implementation (EVA)](https://github.com/georgebv/pyextremes)\n",
    "- **Isolation Forests**: [Intuition and Python Implementation](http://www.extended-cognition.com/2018/11/15/multivariate-outlier-detection-with-isolation-forests/)\n",
    "- **Proximity Based Models with or without PCA:** [Theory PCA](https://en.wikipedia.org/wiki/Principal_component_analysis) | [Theory Euclidean Distance](https://en.wikipedia.org/wiki/Euclidean_distance) | [Theory Mahalanobis Distance](https://nirpyresearch.com/detecting-outliers-using-mahalanobis-distance-pca-python/) | [Python Implementation](https://nirpyresearch.com/detecting-outliers-using-mahalanobis-distance-pca-python/)\n",
    "- **High Dimensional Outlier Detection Methods** (high dimensional sparse data): [Theory HiCS](https://www.ipd.kit.edu/mitarbeiter/muellere/publications/ICDE2012.pdf) | [Why to use HiCS in highly dimensional spaces](https://members.loria.fr/MOBerger/Enseignement/Master2/Exposes/beyer.pdf) | [Python Implementation](https://github.com/KDD-OpenSource/fexum-hics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8.3: Identifying Outliers and Extreme Values\n",
    "\n",
    "We recommend the identification of both, Extreme Values for determined **single features** and Extreme values for a **subset of features**. For this project, we are going to do both:\n",
    "\n",
    "#### 8.3.1. Identifying Outliers and Extreme values for single features:\n",
    "\n",
    "In this case, as a results a combination the insights generated in during the **Data Profiling** process and **business decisions** we are going to focus on identifying outliers for **total_claim_amount**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets start by plotting the distribution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)\n",
    "\n",
    "df['total_claim_amount'].iplot(\n",
    "    mean = 'True',\n",
    "    kind='hist',\n",
    "    bins=100,\n",
    "    xTitle='Total Claim Amount',\n",
    "    linecolor='black',\n",
    "    yTitle='count',\n",
    "    colorscale = 'greens',\n",
    "    title='Histogram of Sale Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this variable has a bimodal distribution, so we are going to split it into two datasets and then conduct the outlier analysis.\n",
    "\n",
    "**Distribution A (<15K)**:\n",
    "\n",
    "In this case we are not going to identify any outliers as the smallest value correspond to a minor, parking accident and the upper threshold is still smaller than the next cluster partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)\n",
    "\n",
    "less_15k = df['total_claim_amount'][df['total_claim_amount']<15000]\n",
    "less_15k.iplot(\n",
    "    mean = 'True',\n",
    "    kind='hist',\n",
    "    bins=100,\n",
    "    xTitle='Total Claim Amount',\n",
    "    linecolor='black',\n",
    "    yTitle='count',\n",
    "    colorscale = 'greens',\n",
    "    title='Histogram of Sale Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution A (>20K)**:\n",
    "\n",
    "In this case we are not going to identify any outliers as the smallest values as we already analyzed them in the previous histogram. Now we are going to focus on the upper side of this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)\n",
    "\n",
    "more_20k = df['total_claim_amount'][df['total_claim_amount']>20000]\n",
    "more_20k.iplot(\n",
    "    mean = 'True',\n",
    "    kind='hist',\n",
    "    bins=100,\n",
    "    xTitle='Total Claim Amount',\n",
    "    linecolor='black',\n",
    "    yTitle='count',\n",
    "    colorscale = 'blues',\n",
    "    title='Histogram of Sale Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Standard Deviation of upper thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_20k_std = statistics.stdev(more_20k)\n",
    "more_20k_mean = statistics.mean(more_20k)\n",
    "\n",
    "upper_threshold_2_5 = more_20k_mean+(2.5*more_20k_std)\n",
    "print(\"- Upper Threshold with 2.5 stds: \", int(upper_threshold_2_5))\n",
    "\n",
    "upper_threshold_3_5 = more_20k_mean+(3.5*more_20k_std)\n",
    "print(\"- Upper Threshold with 3.5 stds: \", int(upper_threshold_3_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there a no values above 3.5 Standard deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Asigning classifications into variables on the original DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do this because we want to generate some exploratory Data Analysis with those variables later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_claim_amount_15k'] = df['total_claim_amount'].apply(lambda x: 1 if x<15000 else 0)\n",
    "print(\"- Total samples smaller than 15k:\", int(sum(df['total_claim_amount_15k'])))\n",
    "\n",
    "df['total_claim_amount_2_5_std'] = df['total_claim_amount'].apply(lambda x: 1 if x<upper_threshold_2_5 else 0)\n",
    "print(\"- Total samples with more than than 2.5std:\", int(len(df) - sum(df['total_claim_amount_2_5_std'])))\n",
    "\n",
    "df['total_claim_amount_3_5_std'] = df['total_claim_amount'].apply(lambda x: 1 if x<upper_threshold_3_5 else 0)\n",
    "print(\"- Total samples with more than than 3.5std:\", int(len(df) - sum(df['total_claim_amount_3_5_std'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percentage of fraud by by total_amount category <15k. | Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "temp = df[['total_claim_amount_15k','fraud_reported']].groupby(['total_claim_amount_15k'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='total_claim_amount_15k',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percentage of fraud by by total_amount category <15k. | Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "temp = df[['total_claim_amount_2_5_std','fraud_reported']].groupby(['total_claim_amount_2_5_std'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='total_claim_amount_2_5_std',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "temp = df[['total_claim_amount_2_5_std','fraud_reported']].groupby(['total_claim_amount_2_5_std'], as_index = False).count().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='total_claim_amount_2_5_std',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.1. Identifying Outliers and Extreme values for a subset of the features:\n",
    "\n",
    "In the **Data Profiling** process, we identified some variables, that we should not use here. \n",
    "* policy_number\n",
    "* policy_bind_date\n",
    "* incident_date\n",
    "* incident_location\n",
    "* auto_model\n",
    "\n",
    "Additionally, we are going to ignore:\n",
    "\n",
    "* fraud_reported\n",
    "* total_claim_amount_15k\n",
    "* total_claim_amount_2_5_std\n",
    "* total_claim_amount_3_5_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ignore_initial_pca = ['policy_number', 'policy_bind_date', 'incident_date', 'incident_location', 'auto_model', 'fraud_reported', 'total_claim_amount_15k', 'total_claim_amount_2_5_std', 'total_claim_amount_3_5_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(features_ignore_initial, errors ='ignore', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need to tokenize the **categorial variables**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorial = ['policy_state', 'policy_csl', 'insured_sex', 'insured_education_level', 'insured_occupation', 'insured_hobbies', 'insured_relationship','incident_type','collision_type','incident_severity','authorities_contacted','incident_state','incident_city','property_damage','police_report_available','auto_make']\n",
    "df2 = pd.get_dummies(df2.drop('fraud_reported', errors ='ignore', axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use **PCA**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Define the PCA object\n",
    "pca = PCA(svd_solver = 'full', random_state=80)\n",
    "# Run PCA on scaled data and obtain the scores array\n",
    "T = pca.fit_transform(StandardScaler().fit_transform(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will use [HDBSCAN](https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=10)\n",
    "clusterer.fit(T[:,:2])\n",
    "\n",
    "print(\"- Number of possible outliers:\", max(clusterer.labels_)+1)\n",
    "print(\"- Number of possible outliers:\", sum(clusterer.labels_ ==-1))\n",
    "\n",
    "colors = [plt.cm.jet(float(i)/max(clusterer.labels_)) for i in clusterer.labels_]\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "with plt.style.context(('ggplot')):\n",
    "    plt.scatter(T[:, 0], T[:, 1], c=colors, edgecolors='k', s=60)\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.title('Score Plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hdbscan_cluster'] = clusterer.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "temp = df[['hdbscan_cluster','fraud_reported']].groupby(['hdbscan_cluster'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "ax = sns.barplot(x='hdbscan_cluster',  y = 'fraud_reported', data=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ignore_initial = ['policy_number', 'policy_bind_date', 'incident_date', 'incident_location','insured_zip', 'auto_model', 'total_claim_amount_15k', 'total_claim_amount_2_5_std', 'total_claim_amount_3_5_std','hdbscan_cluster']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8.3: What can be done with extreme values?\n",
    "\n",
    "There are virtually infinite ways to deal with extreme values. However, one common practice is to research and understand the causes of these in order to determine what do with them. Furthermore, following you will find some of the most common practices:\n",
    "\n",
    "- Use this engine in order to re-direct this datapoints to other processes: **human-in-the-loop** or **heuristics** based approaches.\n",
    "- If the cause of those extreme values can be identified and explained (they have **natural** causes), they can be treated by adding features that capture their behavior and/or adding more samples to this dataset.\n",
    "- In cases where those extreme values were generated because of **non-natural** causes (errors in data pipeline, measurement errors), Data Scientists typically remove those extreme values from the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9:  Working on data split for baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we are not going to do any **model, feature or hyperparameter selection**. Here we just want to have a quick model in order to understand limitations with the dataset and have a ballpark idea on how well the model can be.\n",
    "\n",
    "For this step, we typically recommend having as less **Feature Engineering** as possible, as we want to understand the behavior of the **raw** features. We also recommend using the simplest algorithms available, as we do not want to spend too much time in this process. We typically recommend using simple linear models such as **Linear Regressions** or **Logistic Regressions**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1. Separrating features and targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we do not do anything too special, here we are just separating our **target** from our **features** and ignoring some of the features that cannot be put into the model without preprocessing (**dates, customer_id, etc...**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(features_ignore_initial,errors='ignore', axis = 1)\n",
    "X = df2.drop(target_variable, axis=1)\n",
    "y = df2[target_variable].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2. Defining Split between test/train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if it seems trivial, this is one of the most important steps in the Data Science process, as an error here can mislead and/or make this process more difficult to you, as we can introduce **data leakage** and **underrepresentation** on the training set. These are some of the thinks that we recommend taking into account:\n",
    "\n",
    "- For **categorical** dependent targets, we recommend using stratified splits, as we want to have a similar distribution on both the training and testing datasets.\n",
    "- When you are working with **Time Series**, we recommend doing the splits based on date **cut-off**, as samples of the same period tend to have similar behaviors and in real life we will never have future data to train the models. Thus, the objective of this kind of models is to predict **future** behavior with data from the **past**.\n",
    "- For **Non-Time Series** cases, even though in most cases not involving big data, we do splits based in percentages, this is not always applicable. In cases where you have **2MM observations**, for example, the **20% represents 400k observations** (that seems like a lot). In these cases, you might want to analyze what number of observations make sense in order to do a correct model selection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3. Splitting train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=pd.get_dummies(X.drop('fraud_reported', errors ='ignore', axis = 1))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=t_size, random_state=19, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Creation of baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm = ExplainableBoostingClassifier()\n",
    "ebm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10.1. Evaluating initial model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are to do an initial evaluation of the Performance Metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ef = ebm.predict(X_test)\n",
    "\n",
    "print(\"Training Accuracy: \", ebm.score(X_train, y_train))\n",
    "print('Testing Accuarcy: ', ebm.score(X_test, y_test))\n",
    "\n",
    "# making a classification report\n",
    "cr = classification_report(y_test,  y_pred_ef,target_names=['non-fraud','fraud'])\n",
    "print(cr)\n",
    "\n",
    "# making a confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_ef)\n",
    "sns.heatmap(cm, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11. Logging results into Azure Machine Learning Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting to WorkspaceChoose a logging ops\n",
    "\n",
    "If you want to track or monitor your experiment, you must add code to start logging when you submit the run. The following are ways to trigger the run submission:\n",
    "\n",
    "- **Run.start_logging** - Add logging functions to your training script and start an interactive logging session in the specified experiment. **start_logging** creates an interactive run for use in scenarios such as notebooks. Any metrics that are logged during the session are added to the run record in the experiment.\n",
    "- **ScriptRunConfig** - Add logging functions to your training script and load the entire script folder with the run. **ScriptRunConfig** is a class for setting up configurations for script runs. With this option, you can add monitoring code to be notified of completion or to get a visual widget to monitor.\n",
    "- **Designer logging** - Add logging functions to a drag-&-drop designer pipeline by using the **Execute Python Script** module. Add Python code to log designer experiments.\n",
    "- **AML AutoML** - When we use AutoML, it automatically creates an experiment and registers all the important metrics.\n",
    "\n",
    "You can find more information [Here.](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-track-experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 11.1. Connecting to Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check core SDK version number\n",
    "print(\"You are currently using version\", azureml.core.VERSION, \"of the Azure ML SDK\")\n",
    "print(\"\")\n",
    "\n",
    "ws = Workspace(SUBSCRIPTION_ID, RESOURCE_GROUP, WORKSPACENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 11.2. Generating Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_test,  y_pred_ef,target_names=['non-fraud','fraud'], output_dict =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Fraud\n",
    "non_fraud_precision = cr['non-fraud']['precision']\n",
    "non_fraud_recall = cr['non-fraud']['recall']\n",
    "non_fraud_f1_score = cr['non-fraud']['f1-score']\n",
    "non_fraud_support = cr['non-fraud']['support']\n",
    "\n",
    "# Fraud\n",
    "fraud_precision = cr['fraud']['precision']\n",
    "fraud_recall = cr['fraud']['recall']\n",
    "fraud_f1_score = cr['fraud']['f1-score']\n",
    "fraud_support = cr['fraud']['support']\n",
    "\n",
    "# Macro Average\n",
    "macro_precision = cr['macro avg']['precision']\n",
    "macro_recall = cr['macro avg']['recall']\n",
    "macro_f1_score = cr['macro avg']['f1-score']\n",
    "macro_support = cr['macro avg']['support']\n",
    "\n",
    "# Weighted Average\n",
    "weighted_precision = cr['weighted avg']['precision']\n",
    "weighted_recall = cr['weighted avg']['recall']\n",
    "weighted_f1_score = cr['weighted avg']['f1-score']\n",
    "weighted_support = cr['weighted avg']['support']\n",
    "\n",
    "values_to_log = [non_fraud_precision, non_fraud_recall, non_fraud_f1_score,non_fraud_support, \n",
    "                 fraud_precision, fraud_recall,fraud_f1_score,fraud_support,\n",
    "                macro_precision,macro_recall,macro_f1_score, macro_support,\n",
    "                weighted_precision, weighted_recall, weighted_f1_score, weighted_support]\n",
    "\n",
    "names_to_log = ['non_fraud_precision', 'non_fraud_recall', 'non_fraud_f1_score','non_fraud_support', \n",
    "                 'fraud_precision', 'fraud_recall','fraud_f1_score','fraud_support',\n",
    "                'macro_precision','macro_recall','macro_f1_score', 'macro_support',\n",
    "                'weighted_precision', 'weighted_recall', 'weighted_f1_score', 'weighted_support']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an experiment object from Azure Machine Learning\n",
    "experiment = Experiment(workspace=ws, name=\"train-within-notebook\")\n",
    "\n",
    "# Create a run object in the experiment\n",
    "run =  experiment.start_logging()\n",
    "# Log the algorithm parameter alpha to the run\n",
    "for i in range(0,len(names_to_log)):\n",
    "    run.log(names_to_log[i], values_to_log[i])\n",
    "\n",
    "# Save the model to the outputs directory for capture\n",
    "model_file_name = 'outputs/ebm.pkl'\n",
    "\n",
    "joblib.dump(value = ebm, filename = model_file_name)\n",
    "\n",
    "# upload the model file explicitly into artifacts \n",
    "run.upload_file(name = model_file_name, path_or_stream = model_file_name)\n",
    "\n",
    "# Complete the run\n",
    "run.complete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "022525b1b1b24eabba909440f8ec8983": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "093099241c6b466fb4021cc1d37f3de1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Render HTML: 100%",
       "layout": "IPY_MODEL_2b0ab8cdd45444218ac9229d943ed96a",
       "max": 1,
       "style": "IPY_MODEL_b7655d1f68c64110afc7261e36c865dc",
       "value": 1
      }
     },
     "0f6f4fc8963d4172b589691f3f9746e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_b11ef589a179462b8fcaeb0c7960db2c",
        "IPY_MODEL_9795878f9ee64771b74a6cb829d34939"
       ],
       "layout": "IPY_MODEL_2afeb1a2e1844aa8b2f3e3be8a4dbcca"
      }
     },
     "1f944c55481249abb1c2b27643d612ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "2a8a592b74044e73a13c09aeae276a19": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e92dacfaa7284e879aeeb3b6c124b82c",
       "style": "IPY_MODEL_6f5e4638f47a4493ad262f5419c19a8e",
       "value": " 1/1 [00:31&lt;00:00, 31.84s/it]"
      }
     },
     "2afeb1a2e1844aa8b2f3e3be8a4dbcca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2b0ab8cdd45444218ac9229d943ed96a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3db6c5c09e4b403ebf38bd0bc7ea0982": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4e0ad30d0ac44b15811e69882bfc49e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Generate report structure: 100%",
       "layout": "IPY_MODEL_022525b1b1b24eabba909440f8ec8983",
       "max": 1,
       "style": "IPY_MODEL_1f944c55481249abb1c2b27643d612ce",
       "value": 1
      }
     },
     "4f71a088bc4146cba92b0ad7655fb787": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "54569aff726648298245b84d0e1a8a91": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "59ca5ddb0a714cafa72fe32856ebf0f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6f5e4638f47a4493ad262f5419c19a8e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9795878f9ee64771b74a6cb829d34939": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e143c77cb8504b99bc3a65cb5cd986cb",
       "style": "IPY_MODEL_59ca5ddb0a714cafa72fe32856ebf0f2",
       "value": " 53/53 [00:53&lt;00:00,  1.02s/it, Completed]"
      }
     },
     "ad94c3d18ae244209b218aafa252ec55": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b11ef589a179462b8fcaeb0c7960db2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Summarize dataset: 100%",
       "layout": "IPY_MODEL_3db6c5c09e4b403ebf38bd0bc7ea0982",
       "max": 53,
       "style": "IPY_MODEL_ef18531ffd884e039df56b2258b796f4",
       "value": 53
      }
     },
     "b7655d1f68c64110afc7261e36c865dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "bf6947c3257848f7922c8d32186ffd5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_54569aff726648298245b84d0e1a8a91",
       "style": "IPY_MODEL_ad94c3d18ae244209b218aafa252ec55",
       "value": " 1/1 [00:13&lt;00:00, 13.60s/it]"
      }
     },
     "d2913203bf5042ba978f681cb3898563": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_093099241c6b466fb4021cc1d37f3de1",
        "IPY_MODEL_bf6947c3257848f7922c8d32186ffd5b"
       ],
       "layout": "IPY_MODEL_f15b9e77f52f41218197c3488c3797a3"
      }
     },
     "e143c77cb8504b99bc3a65cb5cd986cb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e37510ff08304267bae375e6efa2fcc6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4e0ad30d0ac44b15811e69882bfc49e5",
        "IPY_MODEL_2a8a592b74044e73a13c09aeae276a19"
       ],
       "layout": "IPY_MODEL_4f71a088bc4146cba92b0ad7655fb787"
      }
     },
     "e92dacfaa7284e879aeeb3b6c124b82c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ef18531ffd884e039df56b2258b796f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "f15b9e77f52f41218197c3488c3797a3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
