# Dataset Questionnaire for Data Ingestion Process

## Overview

Having a clear view of ***business objectives*** and defining achievable goals are important tasks to ensure that results will meet expectations from the business. Deeply understanding the content of your dataset is crucial when identifying future ***risks and limitations*** of your Machine Learning models and processes.

Following you will find a series of questions that, even though in some cases might not be enough, can work as a baseline to help you with both reducing the risks associated with ***unrealistic expectations*** and  with ***limitations of the dataset***. These questions will complement the questions from the **Data Validation phase**.

-------------------------------

## Questions:

### 1. Security of development environment:

- **How are you securing your development environment?** When you use a cloud service, for example, a best practice is to restrict access to only the users who need it. You might also want to restrict network access or securely join resources in your on-premises network with the cloud. You can find more information on how to do it in Azure [Here.](https://docs.microsoft.com/en-us/azure/machine-learning/concept-enterprise-security)
- **Where do you share your code with other parts of the business or processes?** In the enterprise, as part of the development process, people share code and assets in a version control system. [GitHub](https://www.bing.com/search?q=github+introduction&cvid=0af7cc9bbabf4381bcba579b85a5bf82&FORM=ANAB01&PC=U531) and Azure [DevOps](https://docs.microsoft.com/en-us/azure/devops/?view=azure-devops) are examples.
- **How do I protect the assets being generated by my model?** Nobody wants those assets to be publicly available on the internet.
- **How do you store/update the code in this repository?**
- **Do you have a process to avoid exposing credentials and/or other confidential information in your code?** Exposing keys and other credentials can make it easier for somebody to infiltrate your systems.

### 2. Model Version Control:

- **How do you keep model inventory and documentation?** It is very important to have a model inventory and document each version of the models. As you want them to be available in for future audits or rollbacks.
- **How do I decide which versions of the model are going to be kept and which ones are going to be deprecated?** Having a clear testing and validation process is very important, the results obtained here should be as similar as possible to real-life scenarios.
- **Do I have a cleanup process?** Do you have a process in place to cleanup deprecated models?

### 3. Assumptions on the model:
                                                                                             
- **What kind of algorithms or approaches you cannot use in this project?** Sometimes because of regulations, some models are not allowed to use in certain processes.
- **How are you addressing the insights found during the Data Profile phase?** Using those insights is crucial when doing **Feature Engineering**, as most transformations and data processing processes depend on how much impact might have on the models results.
- **Are you tracking model performance in the data anomalies detected in the Model Objective validation phase?** It is recommended to have a platform or system where these results are stored so that you can compare and track them over time. 
- **How are you addressing data anomalies detected in the Model Objective validation phase?** It is recommended to have a process in place to deal with those anomalies, outliers, and extreme values.
- **Did you identify subsets of the data where the model has lower performance results that the overall sample?** This can help in understanding weaknesses of the model.
- **Does your model present a different performance in your subpopulations? How are you evaluating fairness on the models?** How are you evaluating fairness in your model?
- **Do I have any background on the variables/features used in the model?** Is there any theory that supports the features used? Does the use of these features make sense from the business and ethical points of view?
- **What are the limitations of models based in population?** Where should you use these models? In which cases do you recommend not to use this model.

-------------------------------

## Demo:

You can find this exercise for the Demo dataset in the following link: [Model Creation Questionnaire.](model_ov_questionnaire.xlsx)

-------------------------------

## Supervisory Guidance on Model Risk Management (FDIC):

Please go to the following documentation: [FDIC](https://www.fdic.gov/news/financial-institution-letters/2017/fil17022a.pdf)

-------------------------------

## More information:

We recommend reading the following paper: ***Co-Designing Checklists to Understand Organizational Challenges and Opportunities around Fairness in AI***. More information [here](http://www.jennwv.com/papers/checklists.pdf)